【任务名】	url点击数据入库
【时间驱动】	5 9 * * *	运行超时	150分钟	等待超时	0分钟
【运行命令】	cd /home/work/beidou-cron/bin; sh importClickUrl.sh
【日志地址】/home/work/beidou-cron/log/importClickUrl/click${yyyymmdd}.log
【变更库表】	Beidouurl.click{0-99}
【任务依赖】  无
========================================================================================
【任务描述】
该脚本的功能是： 1. 从log平台下载url点击日志。 2. 从db中读取所有物料信息（select id,uid,pid,gid from cprounitstateX）保存在一个info文件中。 3. 合并info文件和url点击日志。 4. 检查合并和文件行数与原始url点击日志行数，如果超过50误差则认为有问题报警。 5. 利用load data将合并后的文件导入beidouurl库中100张click表。 
出错在第三步，程序会load四层级的所有信息，随着物料的增加越来越吃内存，后来把java的-Xmx参数调整到4600M才跑过。后续可以考虑优化java程序。 


==========================================================================================
【报警内容】

【备注】
这个任务执行失败时，一般是OP手动执行，由于要load数据到100张表中，因此某一张表load失败，重跑任务时前面的表都要全部重新load